import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import networkx as nx
from datetime import datetime
import streamlit.components.v1 as components
import numpy as np
from collections import defaultdict
import re
from textblob import TextBlob

# Configura√ß√£o da p√°gina
st.set_page_config(layout="wide", page_title="Plataforma IC Natura")

# Configura√ß√µes e constantes
COMPETITORS = ["O Botic√°rio", "Avon", "Eudora", "MAC", "Quem disse Berenice"]

# Configura√ß√£o da rede sem√¢ntica
SEMANTIC_NETWORK = {
    'Inova√ß√£o': {
        'primary': ['tecnologia', 'inova√ß√£o', 'digital', 'futuro'],
        'related': ['desenvolvimento', 'pesquisa', 'lan√ßamento'],
        'weight': 1.0
    },
    'Sustentabilidade': {
        'primary': ['sustent√°vel', 'eco', 'verde', 'ambiental'],
        'related': ['recicl√°vel', 'natural', 'consciente'],
        'weight': 0.8
    },
    'Experi√™ncia': {
        'primary': ['cliente', 'experi√™ncia', 'jornada', 'atendimento'],
        'related': ['personaliza√ß√£o', 'servi√ßo', 'satisfa√ß√£o'],
        'weight': 0.9
    },
    'Produto': {
        'primary': ['skincare', 'maquiagem', 'perfume', 'tratamento'],
        'related': ['f√≥rmula', 'ingredientes', 'linha'],
        'weight': 0.7
    }
}

# Classifica√ß√£o de a√ß√µes
ACTION_TYPES = {
    'BAU': {
        'keywords': ['regular', 'rotina', 'normal', 'padr√£o'],
        'weight': 0.3,
        'threshold': 0.4
    },
    'Bomba': {
        'keywords': ['inovador', 'disruptivo', 'revolucion√°rio', '√∫nico'],
        'weight': 0.8,
        'threshold': 0.7
    },
    'Ninja': {
        'keywords': ['estrat√©gico', 'silencioso', 'surpresa', 'inesperado'],
        'weight': 0.6,
        'threshold': 0.6
    }
}

class SemanticAnalyzer:
    def __init__(self, semantic_network, action_types):
        self.semantic_network = semantic_network
        self.action_types = action_types
        
    def analyze_text(self, text):
        """Analisa texto e retorna classifica√ß√µes e territ√≥rios"""
        text = text.lower()
        blob = TextBlob(text)
        
        # An√°lise de territ√≥rios
        territory_scores = defaultdict(float)
        for territory, data in self.semantic_network.items():
            primary_score = sum(word in text for word in data['primary']) * data['weight']
            related_score = sum(word in text for word in data['related']) * data['weight'] * 0.7
            territory_scores[territory] = primary_score + related_score
        
        # An√°lise de tipo de a√ß√£o
        action_scores = defaultdict(float)
        for action, data in self.action_types.items():
            score = sum(word in text for word in data['keywords']) * data['weight']
            if score >= data['threshold']:
                action_scores[action] = score
        
        # Identifica principais territ√≥rios e a√ß√£o
        main_territories = [t for t, s in territory_scores.items() if s > 0.5]
        main_action = max(action_scores.items(), key=lambda x: x[1])[0] if action_scores else 'BAU'
        
        return {
            'territories': main_territories,
            'action_type': main_action,
            'sentiment': blob.sentiment.polarity,
            'relevance': max(action_scores.values()) if action_scores else 0.3
        }

def generate_mock_data():
    """Gera dados simulados enriquecidos"""
    # A√ß√µes base
    actions = [
        "Lan√ßamento de nova linha de skincare sustent√°vel",
        "Campanha digital com influenciadores",
        "Expans√£o de lojas no Nordeste",
        "Parceria com marca internacional",
        "Novo app de realidade aumentada",
        "Programa de reciclagem de embalagens",
        "Sistema de refil para perfumes"
    ]
    
    # Cria DataFrame
    data = []
    analyzer = SemanticAnalyzer(SEMANTIC_NETWORK, ACTION_TYPES)
    
    for _ in range(35):
        action = np.random.choice(actions)
        analysis = analyzer.analyze_text(action)
        
        data.append({
            'data': pd.Timestamp('2024-01-01') + pd.Timedelta(days=np.random.randint(0, 35)),
            'empresa': np.random.choice(COMPETITORS),
            'acao': action,
            'territorios': analysis['territories'],
            'tipo': analysis['action_type'],
            'relevancia': max(1, min(5, int(analysis['relevance'] * 5))),
            'sentimento': analysis['sentiment'],
            'engajamento': np.random.randint(100, 10000)
        })
    
    return pd.DataFrame(data)

# Widget do Agente ZAIA
def zaia_widget():
    widget_html = """
        <div>
            <script>
                window.Widget = {
                    AgentURL: "https://platform.zaia.app/embed/chat/36828",
                };
            </script>
            <script src="https://platform.zaia.app/script/widget-loader.js"></script>
        </div>
    """
    components.html(widget_html, height=700)

# Gera rede de conex√µes
def generate_network(data):
    G = nx.Graph()
    
    # Adiciona n√≥s
    for territory in SEMANTIC_NETWORK.keys():
        G.add_node(territory, type='territory')
    
    for competitor in COMPETITORS:
        G.add_node(competitor, type='competitor')
    
    # Adiciona conex√µes baseadas em a√ß√µes
    for _, row in data.iterrows():
        for territory in row['territorios']:
            G.add_edge(row['empresa'], territory, weight=row['relevancia'])
    
    return G

# Carrega dados simulados
movements_data = generate_mock_data()

# Interface principal
st.title("üéØ Plataforma IC Natura")

# Main Content
tabs = st.tabs(["üìä Dashboard", "üîç Fonte de Dados", "üï∏Ô∏è An√°lise Sem√¢ntica", "üí¨ Assistente IA", "üìà Studio"])

# Dashboard Tab
with tabs[0]:
    st.subheader("Overview de Mercado")
    
    # M√©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Movimentos",
            len(movements_data),
            f"+{len(movements_data[movements_data['data'] > pd.Timestamp.now() - pd.Timedelta(days=7)])}"
        )
    
    with col2:
        bomba_count = len(movements_data[movements_data['tipo'] == 'Bomba'])
        st.metric(
            "A√ß√µes Bomba",
            bomba_count,
            f"+{len(movements_data[(movements_data['tipo'] == 'Bomba') & (movements_data['data'] > pd.Timestamp.now() - pd.Timedelta(days=7))])}"
        )
    
    with col3:
        avg_relevance = movements_data['relevancia'].mean()
        st.metric(
            "Relev√¢ncia M√©dia",
            f"{avg_relevance:.1f}",
            f"{(avg_relevance - 3):.1f}"
        )
    
    with col4:
        total_engagement = movements_data['engajamento'].sum()
        st.metric(
            "Engajamento Total",
            f"{total_engagement:,.0f}",
            "12%"
        )
    
    # Visualiza√ß√µes principais
    col1, col2 = st.columns(2)
    
    with col1:
        # Timeline de a√ß√µes
        fig = px.scatter(
            movements_data,
            x='data',
            y='empresa',
            size='relevancia',
            color='tipo',
            title="Timeline de A√ß√µes"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # Heatmap de territ√≥rios por empresa
        territory_data = pd.DataFrame([
            {'empresa': row['empresa'], 'territorio': t}
            for _, row in movements_data.iterrows()
            for t in row['territorios']
        ])
        
        territory_matrix = pd.crosstab(territory_data['empresa'], territory_data['territorio'])
        
        fig = px.imshow(
            territory_matrix,
            title="Intensidade de Atua√ß√£o por Territ√≥rio"
        )
        st.plotly_chart(fig, use_container_width=True)

# Fonte de Dados Tab
with tabs[1]:
    st.subheader("Fonte de Dados")
    
    # Filtros
    col1, col2, col3 = st.columns(3)
    
    with col1:
        selected_companies = st.multiselect(
            "Empresas",
            COMPETITORS,
            default=COMPETITORS[:2]
        )
    
    with col2:
        selected_territories = st.multiselect(
            "Territ√≥rios",
            list(SEMANTIC_NETWORK.keys()),
            default=list(SEMANTIC_NETWORK.keys())[:2]
        )
    
    with col3:
        selected_types = st.multiselect(
            "Tipos de A√ß√£o",
            list(ACTION_TYPES.keys()),
            default=['Bomba', 'Ninja']
        )
    
    # Dados filtrados
    filtered_data = movements_data[
        (movements_data['empresa'].isin(selected_companies)) &
        (movements_data['tipo'].isin(selected_types))
    ]
    
    # Lista de movimentos
    st.markdown("### Movimentos Identificados")
    
    for _, movement in filtered_data.iterrows():
        with st.expander(f"{movement['data'].strftime('%d/%m/%Y')} - {movement['empresa']}: {movement['acao']}"):
            col1, col2 = st.columns([3,1])
            
            with col1:
                st.markdown(f"**Territ√≥rios:** {', '.join(movement['territorios'])}")
                st.markdown(f"**Sentimento:** {movement['sentimento']:.2f}")
                st.markdown(f"**Engajamento:** {movement['engajamento']:,}")
            
            with col2:
                if movement['tipo'] == 'Bomba':
                    st.error(movement['tipo'])
                elif movement['tipo'] == 'Ninja':
                    st.warning(movement['tipo'])
                else:
                    st.info(movement['tipo'])
                st.metric("Relev√¢ncia", movement['relevancia'])

# An√°lise Sem√¢ntica Tab
with tabs[2]:
    st.subheader("An√°lise Sem√¢ntica de Mercado")
    
    # Rede de conex√µes
    st.markdown("### Rede de Conex√µes")
    network = generate_network(movements_data)
    
    # Criar visualiza√ß√£o de rede usando Plotly
    pos = nx.spring_layout(network)
    
    edge_x = []
    edge_y = []
    for edge in network.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])

    node_x = []
    node_y = []
    node_text = []
    node_color = []
    for node in network.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
        if network.nodes[node]['type'] == 'territory':
            node_color.append('red')
        else:
            node_color.append('blue')

    # Criar figura
    fig = go.Figure()
    
    # Adicionar arestas
    fig.add_trace(go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=0.5, color='#888'),
        hoverinfo='none',
        mode='lines'
    ))
    
    # Adicionar n√≥s
    fig.add_trace(go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        hoverinfo='text',
        text=node_text,
        textposition="top center",
        marker=dict(
            size=20,
            color=node_color,
            line_width=2
        )
    ))
    
    fig.update_layout(
        title="Rede de Conex√µes entre Empresas e Territ√≥rios",
        showlegend=False,
        hovermode='closest',
        margin=dict(b=0,l=0,r=0,t=40)
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # An√°lise de clusters
    st.markdown("### Clusters Tem√°ticos")
    
    # Criar matriz de co-ocorr√™ncia
    territories = list(SEMANTIC_NETWORK.keys())
    co_occurrence = np.zeros((len(territories), len(territories)))
    
    for _, row in movements_data.iterrows():
        for t1 in row['territorios']:
            for t2 in row['territorios']:
                if t1 != t2:
                    i = territories.index(t1)
                    j = territories.index(t2)
                    co_occurrence[i][j] += 1
                    co_occurrence[j][i] += 1
    
    fig = px.imshow(
        co_occurrence,
        x=territories,
        y=territories,
        title="Matriz de Co-ocorr√™ncia de Territ√≥rios"
    )
    st.plotly_chart(fig, use_container_width=True)

# Assistente IA Tab
with tabs[3]:
    st.subheader("üí¨ Assistente Natura")
    zaia_widget()

# Studio Tab
with tabs[4]:
    st.subheader("Data Studio")
    
    analysis_type = st.selectbox(
        "Tipo de An√°lise",
        ["An√°lise Competitiva", "Territ√≥rio Deep Dive", "Tend√™ncias Emergentes"]
    )
    
    if analysis_type == "An√°lise Competitiva":
        st.markdown("### An√°lise Competitiva")
        
        # M√©tricas por empresa
        for competitor in selected_companies:
            comp_data = movements_data[movements_data['empresa'] == competitor]
            
            st.markdown(f"#### {competitor}")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Total de A√ß√µes", len(comp_data))
            with col2:
                st.metric("Relev√¢ncia M√©dia", f"{comp_data['relevancia'].mean():.1f}")
            with col3:
                st.metric("Engajamento Total", f"{comp_data['engajamento'].sum():,}")
            
            # Gr√°fico de a√ß√µes por territ√≥rio
            territory_counts = pd.DataFrame([
                {'territorio': t}
                for _, row in comp_data.iterrows()
                for t in row['territorios']
            ])
            
            if not territory_counts.empty:
                fig = px.bar(
                    territory_counts['territorio'].value_counts().reset_index(),
                    x='index',
                    y='territorio',
                    title=f"A√ß√µes por Territ√≥rio - {competitor}"
                )
                st.plotly_chart(fig, use_container_width=True)
    
    elif analysis_type == "Territ√≥rio Deep Dive":
        st.markdown("### An√°lise de Territ√≥rio")
        
        selected_territory = st.selectbox(
            "Selecione o Territ√≥rio",
            list(SEMANTIC_NETWORK.keys())
        )
        
        # Filtrar a√ß√µes do territ√≥rio
        territory_actions = movements_data[movements_data['territorios'].apply(lambda x: selected_territory in x)]
        
        # M√©tricas do territ√≥rio
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Total de A√ß√µes", len(territory_actions))
        with col2:
            st.metric("Relev√¢ncia M√©dia", f"{territory_actions['relevancia'].mean():.1f}")
        with col3:
            st.metric("Engajamento Total", f"{territory_actions['engajamento'].sum():,}")
        
        # Timeline do territ√≥rio
        fig = px.scatter(
            territory_actions,
            x='data',
            y='empresa',
            size='relevancia',
            color='tipo',
            title=f"Timeline de A√ß√µes - {selected_territory}"
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # An√°lise de palavras-chave
        st.markdown("#### Palavras-chave Relacionadas")
        st.write(f"Prim√°rias: {', '.join(SEMANTIC_NETWORK[selected_territory]['primary'])}")
        st.write(f"Relacionadas: {', '.join(SEMANTIC_NETWORK[selected_territory]['related'])}")
    
    else:  # Tend√™ncias Emergentes
        st.markdown("### Tend√™ncias Emergentes")
        
        # An√°lise temporal de territ√≥rios
        territory_trends = pd.DataFrame([
            {'data': row['data'], 'territorio': t, 'relevancia': row['relevancia']}
            for _, row in movements_data.iterrows()
            for t in row['territorios']
        ])
        
        # Agregar por semana
        territory_trends['semana'] = territory_trends['data'].dt.isocalendar().week
        weekly_trends = territory_trends.groupby(['semana', 'territorio'])['relevancia'].mean().reset_index()
        
        fig = px.line(
            weekly_trends,
            x='semana',
            y='relevancia',
            color='territorio',
            title="Evolu√ß√£o de Relev√¢ncia por Territ√≥rio"
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Identificar tend√™ncias emergentes
        st.markdown("#### Tend√™ncias Identificadas")
        
        last_week = territory_trends['semana'].max()
        previous_week = last_week - 1
        
        for territory in SEMANTIC_NETWORK.keys():
            last_week_data = weekly_trends[
                (weekly_trends['semana'] == last_week) &
                (weekly_trends['territorio'] == territory)
            ]
            previous_week_data = weekly_trends[
                (weekly_trends['semana'] == previous
